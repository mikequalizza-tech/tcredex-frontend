# tCredex - Robots.txt
# Protect sensitive business data from scraping

# Block all crawlers from sensitive areas
User-agent: *
Disallow: /api/
Disallow: /dashboard/
Disallow: /closing-room/
Disallow: /intake/
Disallow: /messages/
Disallow: /deals/new
Disallow: /onboarding/
Disallow: /investor/
Disallow: /_next/
Disallow: /admin/

# Block known bad bots entirely
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: SearchmetricsBot
Disallow: /

User-agent: serpstatbot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: GPTBot
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

User-agent: Google-Extended
Disallow: /

# No sitemap - we don't want to advertise our URL structure
# Sitemap: none
